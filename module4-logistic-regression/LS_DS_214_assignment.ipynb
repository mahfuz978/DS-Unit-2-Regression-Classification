{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lambda School Data Science\n",
    "\n",
    "*Unit 2, Sprint 1, Module 4*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7IXUfiQ2UKj6"
   },
   "source": [
    "# Logistic Regression\n",
    "\n",
    "\n",
    "## Assignment\n",
    "\n",
    "- [ ] Watch Aaron's [video #1](https://www.youtube.com/watch?v=pREaWFli-5I) (12 minutes) & [video #2](https://www.youtube.com/watch?v=bDQgVt4hFgY) (9 minutes) to learn about the mathematics of Logistic Regression.\n",
    "- [ ] [Sign up for a Kaggle account](https://www.kaggle.com/), if you donâ€™t already have one. Go to our Kaggle InClass competition website. You will be given the URL in Slack. Go to the Rules page. Accept the rules of the competition.\n",
    "- [ ] Do train/validate/test split with the Tanzania Waterpumps data.\n",
    "- [ ] Begin with baselines for classification.\n",
    "- [ ] Use scikit-learn for logistic regression.\n",
    "- [ ] Get your validation accuracy score.\n",
    "- [ ] Submit your predictions to our Kaggle competition. (Go to our Kaggle InClass competition webpage. Use the blue **Submit Predictions** button to upload your CSV file. Or you can use the Kaggle API to submit your predictions.)\n",
    "- [ ] Commit your notebook to your fork of the GitHub repo.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## Stretch Goals\n",
    "\n",
    "- [ ] Add your own stretch goal(s) !\n",
    "- [ ] Clean the data. For ideas, refer to [The Quartz guide to bad data](https://github.com/Quartz/bad-data-guide),  a \"reference to problems seen in real-world data along with suggestions on how to resolve them.\" One of the issues is [\"Zeros replace missing values.\"](https://github.com/Quartz/bad-data-guide#zeros-replace-missing-values)\n",
    "- [ ] Make exploratory visualizations.\n",
    "- [ ] Do one-hot encoding. For example, you could try `quantity`, `basin`, `extraction_type_class`, and more. (But remember it may not work with high cardinality categoricals.)\n",
    "- [ ] Do [feature scaling](https://scikit-learn.org/stable/modules/preprocessing.html).\n",
    "- [ ] Get and plot your coefficients.\n",
    "- [ ] Try [scikit-learn pipelines](https://scikit-learn.org/stable/modules/compose.html).\n",
    "\n",
    "---\n",
    "\n",
    "## Data Dictionary \n",
    "\n",
    "### Features\n",
    "\n",
    "Your goal is to predict the operating condition of a waterpoint for each record in the dataset. You are provided the following set of information about the waterpoints:\n",
    "\n",
    "- `amount_tsh` : Total static head (amount water available to waterpoint)\n",
    "- `date_recorded` : The date the row was entered\n",
    "- `funder` : Who funded the well\n",
    "- `gps_height` : Altitude of the well\n",
    "- `installer` : Organization that installed the well\n",
    "- `longitude` : GPS coordinate\n",
    "- `latitude` : GPS coordinate\n",
    "- `wpt_name` : Name of the waterpoint if there is one\n",
    "- `num_private` :  \n",
    "- `basin` : Geographic water basin\n",
    "- `subvillage` : Geographic location\n",
    "- `region` : Geographic location\n",
    "- `region_code` : Geographic location (coded)\n",
    "- `district_code` : Geographic location (coded)\n",
    "- `lga` : Geographic location\n",
    "- `ward` : Geographic location\n",
    "- `population` : Population around the well\n",
    "- `public_meeting` : True/False\n",
    "- `recorded_by` : Group entering this row of data\n",
    "- `scheme_management` : Who operates the waterpoint\n",
    "- `scheme_name` : Who operates the waterpoint\n",
    "- `permit` : If the waterpoint is permitted\n",
    "- `construction_year` : Year the waterpoint was constructed\n",
    "- `extraction_type` : The kind of extraction the waterpoint uses\n",
    "- `extraction_type_group` : The kind of extraction the waterpoint uses\n",
    "- `extraction_type_class` : The kind of extraction the waterpoint uses\n",
    "- `management` : How the waterpoint is managed\n",
    "- `management_group` : How the waterpoint is managed\n",
    "- `payment` : What the water costs\n",
    "- `payment_type` : What the water costs\n",
    "- `water_quality` : The quality of the water\n",
    "- `quality_group` : The quality of the water\n",
    "- `quantity` : The quantity of water\n",
    "- `quantity_group` : The quantity of water\n",
    "- `source` : The source of the water\n",
    "- `source_type` : The source of the water\n",
    "- `source_class` : The source of the water\n",
    "- `waterpoint_type` : The kind of waterpoint\n",
    "- `waterpoint_type_group` : The kind of waterpoint\n",
    "\n",
    "### Labels\n",
    "\n",
    "There are three possible values:\n",
    "\n",
    "- `functional` : the waterpoint is operational and there are no repairs needed\n",
    "- `functional needs repair` : the waterpoint is operational, but needs repairs\n",
    "- `non functional` : the waterpoint is not operational\n",
    "\n",
    "--- \n",
    "\n",
    "## Generate a submission\n",
    "\n",
    "Your code to generate a submission file may look like this:\n",
    "\n",
    "```python\n",
    "# estimator is your model or pipeline, which you've fit on X_train\n",
    "\n",
    "# X_test is your pandas dataframe or numpy array, \n",
    "# with the same number of rows, in the same order, as test_features.csv, \n",
    "# and the same number of columns, in the same order, as X_train\n",
    "\n",
    "y_pred = estimator.predict(X_test)\n",
    "\n",
    "\n",
    "# Makes a dataframe with two columns, id and status_group, \n",
    "# and writes to a csv file, without the index\n",
    "\n",
    "sample_submission = pd.read_csv('sample_submission.csv')\n",
    "submission = sample_submission.copy()\n",
    "submission['status_group'] = y_pred\n",
    "submission.to_csv('your-submission-filename.csv', index=False)\n",
    "```\n",
    "\n",
    "If you're working locally, the csv file is saved in the same directory as your notebook.\n",
    "\n",
    "If you're using Google Colab, you can use this code to download your submission csv file.\n",
    "\n",
    "```python\n",
    "from google.colab import files\n",
    "files.download('your-submission-filename.csv')\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o9eSnDYhUGD7"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "import sys\n",
    "\n",
    "# If you're on Colab:\n",
    "if 'google.colab' in sys.modules:\n",
    "    DATA_PATH = 'https://raw.githubusercontent.com/LambdaSchool/DS-Unit-2-Applied-Modeling/master/data/'\n",
    "    !pip install category_encoders==2.*\n",
    "\n",
    "# If you're working locally:\n",
    "else:\n",
    "    DATA_PATH = '../data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ipBYS77PUwNR"
   },
   "outputs": [],
   "source": [
    "# Ignore this Numpy warning when using Plotly Express:\n",
    "# FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=FutureWarning, module='numpy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QJBD4ruICm1m"
   },
   "outputs": [],
   "source": [
    "# Read the Tanzania Waterpumps data\n",
    "# train_features.csv : the training set features\n",
    "# train_labels.csv : the training set labels\n",
    "# test_features.csv : the test set features\n",
    "# sample_submission.csv : a sample submission file in the correct format\n",
    "    \n",
    "import pandas as pd\n",
    "\n",
    "train_features = pd.read_csv(DATA_PATH+'waterpumps/train_features.csv')\n",
    "train_labels = pd.read_csv(DATA_PATH+'waterpumps/train_labels.csv')\n",
    "test_features = pd.read_csv(DATA_PATH+'waterpumps/test_features.csv')\n",
    "sample_submission = pd.read_csv(DATA_PATH+'waterpumps/waterpumps/sample_submission.csv')\n",
    "\n",
    "assert train_features.shape == (59400, 40)\n",
    "assert train_labels.shape == (59400, 2)\n",
    "assert test_features.shape == (14358, 40)\n",
    "assert sample_submission.shape == (14358, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2Amxyx3xphbb"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "assignment_regression_classification_4.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
